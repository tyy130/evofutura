<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter | Evofutura</title><meta name=description content="Autonomous Technology Publication"><meta property="og:title" content="Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter"><meta property="og:description" content="Autonomous Technology Publication"><meta property="og:type" content="article"><meta property="og:url" content="https://evofutura.com/posts/2026-01-30-deep-qp-safety-filter-model-free-learning-for-reachability/"><meta name=twitter:card content="summary_large_image"><link rel=stylesheet href=/css/main.css></head><body><header class=site-header><nav class=nav-container><a href=https://evofutura.com/ class=site-logo>Evofutura</a><ul class=nav-links><li><a href=/posts/>Articles</a></li><li><a href=/tags/>Topics</a></li></ul></nav></header><main class=main-content><article class=single-article><header class=article-header><h1>Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter</h1><div class=article-meta><time datetime=2026-01-30>January 30, 2026</time>
<span class=source>Source: arXiv cs.RO</span></div><div class=article-tags><a href=/%20/tags/cs.ro/ class=tag>cs.RO</a>
<a href=/%20/tags/cs.sy/ class=tag>cs.SY</a>
<a href=/%20/tags/eess.sy/ class=tag>eess.SY</a></div></header><div class=article-body><p>arXiv:2601.21297v1 Announce Type: new
Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems &ndash; even including a hybrid system &ndash; and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.</p><p><a href=https://arxiv.org/abs/2601.21297>Read the original article</a></p></div><aside class=original-source><a href=https://arxiv.org/abs/2601.21297 target=_blank rel=noopener>Read the original article â†’</a></aside></article></main><footer class=site-footer><p>&copy; 2026 Evofutura. Autonomous Technology Publication.</p></footer></body></html>