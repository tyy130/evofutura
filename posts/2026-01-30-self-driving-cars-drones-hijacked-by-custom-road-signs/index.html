<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Self-driving cars, drones hijacked by custom road signs | Evofutura</title><meta name=description content="Autonomous Technology Publication"><meta property="og:title" content="Self-driving cars, drones hijacked by custom road signs"><meta property="og:description" content="Autonomous Technology Publication"><meta property="og:type" content="article"><meta property="og:url" content="https://evofutura.com/posts/2026-01-30-self-driving-cars-drones-hijacked-by-custom-road-signs/"><meta property="og:image" content="https://res.cloudinary.com/dg7khxdal/image/upload/v1769802707/evofutura/uploads/2026/01/self-driving-cars-drones-hijacked-by-custom-road.jpg"><meta name=twitter:card content="summary_large_image"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel=stylesheet><link rel=stylesheet href=/%20css/main.css></head><body><a href=#main-content class=skip-to-content>Skip to content</a><header class=site-header><nav class=nav-container><a href=https://evofutura.com/ class=site-logo>Evofutura</a><ul class=nav-links><li><a href=/%20posts/>Articles</a></li><li><a href=/%20tags/>Topics</a></li></ul></nav></header><main id=main-content class=main-content><div class=reading-progress id=reading-progress></div><article class=single-article><header class=article-header><h1>Self-driving cars, drones hijacked by custom road signs</h1><div class=article-meta><time datetime=2026-01-30>January 30, 2026</time>
<span class=read-time>2 min read</span>
<span class=source>via TheRegister.com</span></div><div class=article-tags><a href=/tags/robotics/ class=tag>robotics</a></div></header><figure class=featured-image><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769802707/evofutura/uploads/2026/01/self-driving-cars-drones-hijacked-by-custom-road.jpg alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><figcaption>Source: TheRegister.com</figcaption></figure><div class=article-body><p>Indirect prompt injection occurs when a bot takes input data and interprets it as a command. We&rsquo;ve seen this problem numerous times when AI bots were fed prompts via web pages or PDFs they read. Now, academics have shown that self-driving cars and autonomous drones will follow illicit instructions that have been written onto road signs.</p><p>In a new class of attack on AI systems, troublemakers can carry out these environmental indirect prompt injection attacks to hijack decision-making processes.</p><p>Potential consequences include self-driving cars proceeding through crosswalks, even if a person was crossing, or tricking drones that are programmed to follow police cars into following a different vehicle entirely.</p><p>The researchers at the University of California, Santa Cruz, and Johns Hopkins showed that, in simulated trials, AI systems and the large vision language models (LVLMs) underpinning them would reliably follow instructions if displayed on signs held up in their camera&rsquo;s view.</p><p>They used AI to tweak the commands displayed on the signs, such as &ldquo;proceed&rdquo; and &ldquo;turn left,&rdquo; to maximize the probability of the AI system registering it as a command, and achieved success in multiple languages.</p><p>Commands in Chinese, English, Spanish, and Spanglish (a mix of Spanish and English words) all seemed to work.</p><p>As well as tweaking the prompt itself, the researchers used AI to change how the text appeared - fonts, colors, and placement of the signs were all manipulated for maximum efficacy.</p><p>The team behind it named their methods CHAI, an acronym for &ldquo;command hijacking against embodied AI.&rdquo;</p><p>While developing CHAI, they found that the prompt itself had the biggest impact on success, but the way in which it appeared on the sign could also make or break an attack, although it is not clear why.</p><p>The researchers tested the idea of manipulating AI thinking using signs in both virtual and physical scenarios.</p><p>Of course, it would be irresponsible to see if a self-driving car would run som&mldr;</p><p><a href=https://www.theregister.com/2026/01/30/road_sign_hijack_ai/>Read the original article</a></p></div><aside class=original-source><a href=https://www.theregister.com/2026/01/30/road_sign_hijack_ai/ target=_blank rel="noopener noreferrer">Read the original article →</a></aside><section class=related-articles><h2>More Articles</h2><div class=related-grid><a class=related-card href=https://evofutura.com/posts/2026-01-30-more-ai-security-noise-chatbots-going-rogue/><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769808516/evofutura/uploads/2026/01/more-ai-security-noise-chatbots-going-rogue.jpg alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><div class=related-card-content><h3>More AI security noise - chatbots going rogue</h3><time datetime=2026-01-30>Jan 30, 2026</time></div></a><a class=related-card href=https://evofutura.com/posts/2026-01-30-a-former-google-engineer-was-found-guilty-of-stealing-artifi/><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769808519/evofutura/uploads/2026/01/a-former-google-engineer-was-found-guilty-of-steal.webp alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><div class=related-card-content><h3>A former Google engineer was found guilty of stealing …</h3><time datetime=2026-01-30>Jan 30, 2026</time></div></a><a class=related-card href=https://evofutura.com/posts/2026-01-30-these-quiet-forces-will-reshape-used-car-dealer-performance/><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769808520/evofutura/uploads/2026/01/these-quiet-forces-will-reshape-used-car-dealer-pe.webp alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><div class=related-card-content><h3>These quiet forces will reshape used car dealer performance …</h3><time datetime=2026-01-30>Jan 30, 2026</time></div></a></div></section></article><script>(function(){const e=document.getElementById("reading-progress");if(!e)return;function t(){const n=window.scrollY,t=document.documentElement.scrollHeight-window.innerHeight,s=t>0?n/t*100:0;e.style.width=Math.min(100,s)+"%"}window.addEventListener("scroll",t,{passive:!0}),t()})()</script></main><footer class=site-footer><div class=footer-container><div class=footer-brand><a href=https://evofutura.com/ class=footer-logo>Evofutura</a><p>Autonomous Technology Publication covering AI research, robotics, and the future of intelligent
systems.</p></div><div class=footer-topics><h4>Topics</h4><ul><li><a href=/%20tags/ai-research>AI Research</a></li><li><a href=/%20tags/robotics>Robotics</a></li><li><a href=/%20tags/industry>Industry</a></li><li><a href=/%20tags/policy>Policy</a></li><li><a href=/%20tags/products>Products</a></li></ul></div><div class=footer-links><h4>Connect</h4><ul><li><a href=/%20index.xml>RSS Feed</a></li><li><a href=/%20posts/>All Articles</a></li></ul></div></div><div class=footer-bottom><p>&copy; 2026 Evofutura. All rights reserved.</p></div></footer></body></html>