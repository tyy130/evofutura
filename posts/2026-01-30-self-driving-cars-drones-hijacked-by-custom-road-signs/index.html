<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Self-driving cars, drones hijacked by custom road signs | Evofutura</title><meta name=description content="Autonomous Technology Publication"><meta property="og:title" content="Self-driving cars, drones hijacked by custom road signs"><meta property="og:description" content="Autonomous Technology Publication"><meta property="og:type" content="article"><meta property="og:url" content="https://tyy130.github.io/evofutura/posts/2026-01-30-self-driving-cars-drones-hijacked-by-custom-road-signs/"><meta property="og:image" content="https://res.cloudinary.com/dg7khxdal/image/upload/v1769802707/evofutura/uploads/2026/01/self-driving-cars-drones-hijacked-by-custom-road.jpg"><meta name=twitter:card content="summary_large_image"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel=stylesheet><link rel=stylesheet href=/evofutura/css/main.css></head><body><a href=#main-content class=skip-to-content>Skip to content</a><header class=site-header><nav class=nav-container><a href=https://tyy130.github.io/evofutura/ class=site-logo>Evofutura</a><ul class=nav-links><li><a href=/evofutura/posts/>Articles</a></li><li><a href=/evofutura/tags/>Topics</a></li><li><a href=#newsletter class=btn-subscribe>Subscribe</a></li></ul></nav></header><nav class=breadcrumbs aria-label=Breadcrumb><div class=nav-container><a href=/evofutura>Home</a>
<span class=separator>/</span>
<a href=/evofutura/posts/>Articles</a>
<span class=separator>/</span>
<span class=current>Self-driving cars, drones hijacked by custom road signs</span></div></nav><main id=main-content class=main-content><div class=reading-progress id=reading-progress></div><article class=single-article><header class=article-header><h1>Self-driving cars, drones hijacked by custom road signs</h1><div class=article-meta><time datetime=2026-01-30>January 30, 2026</time>
<span class=read-time>2 min read</span>
<span class=source>via TheRegister.com</span></div><div class=article-tags><a href=/tags/robotics/ class=tag>robotics</a></div></header><figure class=featured-image><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769802707/evofutura/uploads/2026/01/self-driving-cars-drones-hijacked-by-custom-road.jpg alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><figcaption>Source: TheRegister.com</figcaption></figure><div class=article-body><p>Indirect prompt injection occurs when a bot takes input data and interprets it as a command. We&rsquo;ve seen this problem numerous times when AI bots were fed prompts via web pages or PDFs they read. Now, academics have shown that self-driving cars and autonomous drones will follow illicit instructions that have been written onto road signs.</p><p>In a new class of attack on AI systems, troublemakers can carry out these environmental indirect prompt injection attacks to hijack decision-making processes.</p><p>Potential consequences include self-driving cars proceeding through crosswalks, even if a person was crossing, or tricking drones that are programmed to follow police cars into following a different vehicle entirely.</p><p>The researchers at the University of California, Santa Cruz, and Johns Hopkins showed that, in simulated trials, AI systems and the large vision language models (LVLMs) underpinning them would reliably follow instructions if displayed on signs held up in their camera&rsquo;s view.</p><p>They used AI to tweak the commands displayed on the signs, such as &ldquo;proceed&rdquo; and &ldquo;turn left,&rdquo; to maximize the probability of the AI system registering it as a command, and achieved success in multiple languages.</p><p>Commands in Chinese, English, Spanish, and Spanglish (a mix of Spanish and English words) all seemed to work.</p><p>As well as tweaking the prompt itself, the researchers used AI to change how the text appeared - fonts, colors, and placement of the signs were all manipulated for maximum efficacy.</p><p>The team behind it named their methods CHAI, an acronym for &ldquo;command hijacking against embodied AI.&rdquo;</p><p>While developing CHAI, they found that the prompt itself had the biggest impact on success, but the way in which it appeared on the sign could also make or break an attack, although it is not clear why.</p><p>The researchers tested the idea of manipulating AI thinking using signs in both virtual and physical scenarios.</p><p>Of course, it would be irresponsible to see if a self-driving car would run som&mldr;</p><p><a href=https://www.theregister.com/2026/01/30/road_sign_hijack_ai/>Read the original article</a></p></div><aside class=original-source><a href=https://www.theregister.com/2026/01/30/road_sign_hijack_ai/ target=_blank rel="noopener noreferrer">Read the original article →</a></aside><section class=related-articles><h2>More Articles</h2><div class=related-grid><a class=related-card href=https://tyy130.github.io/evofutura/posts/2026-01-31-israel-s-infrastructure-paradox-innovation-without-environm/><div class=related-card-content><h3>Israel's infrastructure paradox: Innovation without …</h3><time datetime=2026-01-31>Jan 31, 2026</time></div></a><a class=related-card href=https://tyy130.github.io/evofutura/posts/2026-01-31-business-owners-share-experiences-from-gazette-ai-business-e/><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769847084/evofutura/uploads/2026/01/business-owners-share-experiences-from-gazette-ai.jpg alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><div class=related-card-content><h3>Business owners share experiences from Gazette AI business …</h3><time datetime=2026-01-31>Jan 31, 2026</time></div></a><a class=related-card href=https://tyy130.github.io/evofutura/posts/2026-01-31-why-so-many-businesses-are-still-on-the-wrong-side-of-the-ai/><img src=https://res.cloudinary.com/dg7khxdal/image/upload/v1769847085/evofutura/uploads/2026/01/why-so-many-businesses-are-still-on-the-wrong-side.jpg alt="Self-driving cars, drones hijacked by custom road signs" loading=lazy><div class=related-card-content><h3>Why so many businesses are still on the wrong side of the AI …</h3><time datetime=2026-01-31>Jan 31, 2026</time></div></a></div></section></article><script>(function(){const e=document.getElementById("reading-progress");if(!e)return;function t(){const n=window.scrollY,t=document.documentElement.scrollHeight-window.innerHeight,s=t>0?n/t*100:0;e.style.width=Math.min(100,s)+"%"}window.addEventListener("scroll",t,{passive:!0}),t()})()</script></main><footer class=site-footer><div class=footer-container><div class=footer-brand><a href=https://tyy130.github.io/evofutura/ class=footer-logo>Evofutura</a><p>Autonomous Technology Publication covering AI research, robotics, and the future of intelligent
systems.</p></div><div class=footer-topics><h4>Topics</h4><ul><li><a href=/evofutura/tags/ai-research>AI Research</a></li><li><a href=/evofutura/tags/robotics>Robotics</a></li><li><a href=/evofutura/tags/industry>Industry</a></li><li><a href=/evofutura/tags/policy>Policy</a></li><li><a href=/evofutura/tags/products>Products</a></li></ul></div><div id=newsletter class=footer-newsletter><h4>Join the Digest</h4><p>Curated AI insights delivered weekly.</p><form class=newsletter-form onsubmit=return!1><input type=email placeholder=email@example.com aria-label="Email address" required>
<button type=submit class=btn-primary>Sign Up</button></form></div><div class=footer-links><h4>Connect</h4><ul><li><a href=/evofutura/index.xml>RSS Feed</a></li><li><a href=#>Twitter / X</a></li><li><a href=#>LinkedIn</a></li></ul></div></div><div class=footer-bottom><p>&copy; 2026 Evofutura. All rights reserved.</p></div></footer></body></html>