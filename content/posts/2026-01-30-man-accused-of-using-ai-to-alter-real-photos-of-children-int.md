---
date: '2026-01-30T19:15:11+00:00'
draft: false
image: https://res.cloudinary.com/dg7khxdal/image/upload/v1769802024/evofutura/uploads/2026/01/man-accused-of-using-ai-to-alter-real-photos-of-ch.jpg
image_credit: 'Source: KUSA.com'
source_name: KUSA.com
source_url: https://www.9news.com/article/news/crime/ai-alter-real-photos-explicit-images/73-5e7cb519-1844-47ba-9cb0-02023c99b5b8
title: Man accused of using AI to alter real photos of children into explicit images
---

BOULDER COUNTY, Colo. -- A 72-year-old Boulder County man has been arrested and is accused of using AI to create sexually explicit images of children, the sheriff's office announced.

Daniel Fairchild was arrested Friday on a warrant for 23 counts of sexual exploitation of a child relating to the creation of child sexually exploitative material (CSEM) using online generative artificial intelligence (GenAI) tools.

It's one of the first full investigations by the Boulder County Digital Forensics Lab (BCDFL) involving the use of generative AI to create contraband material. In this particular case, investigators believe photographs of real children were altered using generative AI to create nude and sexually exploitative images of them.

The investigation began after the Colorado Internet Crimes Against Children (ICAC) Task Force received information from the National Center for Missing and Exploited Children (NCMEC) about possible sexual exploitation of a child occurring via the online platform "PicsArt."

PicsArt reported the potential violations to NCMEC after flagging the account and images

After learning the account was possibly associated with a person in the Boulder County area, the Colorado ICAC sent the tip to county authorities for further investigation.

As a result of their investigation, a search warrant was served at Fairchild's residence on South 39th Street in Boulder on Jan. 15. They gathered enough evidence through the search to issue an arrest warrant for Fairchild, who turned himself in on Friday.

If you suspect a child is being sexually exploited online, you can report it online at NCMEC's CyberTipLine website or by calling 1-800-THE-LOST.

[Read the original article](https://www.9news.com/article/news/crime/ai-alter-real-photos-explicit-images/73-5e7cb519-1844-47ba-9cb0-02023c99b5b8)